{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q --progress-bar on \"git+https://github.com/ibm-granite-community/utils.git\" \\\n",
    "    transformers \\\n",
    "    pillow \\\n",
    "    langchain_community \\\n",
    "    langchain_huggingface \\\n",
    "    langchain_milvus \\\n",
    "    docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f312a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install pymupdf\n",
    "!pip install frontend\n",
    "!pip install pytesseract\n",
    "!pip install langchain_ibm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d498528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating image JSON: 100%|██████████| 39/39 [00:00<00:00, 53.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete; vector DB ready.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: Preprocessing with Page Limit, Inline Color Tagging + Image → JSON ===\n",
    "\n",
    "import os\n",
    "# Suppress Milvus logs and disable HuggingFace tokenizer parallelism\n",
    "os.environ[\"GLOG_minloglevel\"] = \"3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pdf_path = \"CSR-ACX7024-configuration-guide-v1.1.pdf\"\n",
    "\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import requests\n",
    "import csv\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_milvus import Milvus\n",
    "from langchain.schema import Document\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat, DocumentStream\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n",
    "from docling_core.types.doc.document import TableItem\n",
    "from langchain_core.documents import Document as LangDocument\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# — Configurable: only process the first N pages (None = all) —\n",
    "max_pages = 5  # set to an int to limit pages, or None for all\n",
    "\n",
    "# — Vision-Instruct Setup —\n",
    "\n",
    "def get_iam_access_token(api_key: str) -> str:\n",
    "    resp = requests.post(\n",
    "        \"https://iam.cloud.ibm.com/identity/token\",\n",
    "        data={\"apikey\": api_key, \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\"},\n",
    "        headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"access_token\"]\n",
    "\n",
    "VISION_API_KEY    = os.getenv(\"WATSONX_API_KEY\")\n",
    "VISION_PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "VISION_MODEL_ID   = \"meta-llama/llama-3-2-90b-vision-instruct\"\n",
    "VISION_TOKEN      = get_iam_access_token(VISION_API_KEY)\n",
    "\n",
    "# — CLI Extraction Setup —\n",
    "\n",
    "PROMPT_RX = re.compile(r'^[\\w\\-\\./]+@[\\w\\-\\./]+[>%#]\\s+.+')\n",
    "CONFIG_RX = re.compile(r'^\\s*(?:set|delete|show|request|clear|commit|rollback)\\s+.+', re.IGNORECASE)\n",
    "\n",
    "def is_cli(text: str) -> bool:\n",
    "    return bool(PROMPT_RX.match(text.strip()) or CONFIG_RX.match(text.strip()))\n",
    "\n",
    "def extract_colored_cli_spans(pdf_bytes: bytes):\n",
    "    import fitz\n",
    "    doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
    "    spans = []\n",
    "    for page_idx, page in enumerate(doc, start=1):\n",
    "        if max_pages and page_idx > max_pages:\n",
    "            break\n",
    "        for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "            if block[\"type\"] != 0:\n",
    "                continue\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    txt = span[\"text\"].strip()\n",
    "                    if not is_cli(txt):\n",
    "                        continue\n",
    "                    c = span.get(\"color\", 0)\n",
    "                    r, g, b = (c >> 16 & 0xFF, c >> 8 & 0xFF, c & 0xFF)\n",
    "                    if r < 50 and g < 50 and b < 50:\n",
    "                        continue\n",
    "                    spans.append({\"page\": page_idx, \"cli\": txt, \"color\": (r, g, b)})\n",
    "    doc.close()\n",
    "    return spans\n",
    "\n",
    "def save_pdf_as_txt(pdf_path: str, txt_path: str):\n",
    "    import fitz\n",
    "    doc = fitz.open(pdf_path)\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as out:\n",
    "        for i, p in enumerate(doc, start=1):\n",
    "            if max_pages and i > max_pages:\n",
    "                break\n",
    "            out.write(p.get_text())\n",
    "            out.write(\"\\f\")\n",
    "    doc.close()\n",
    "\n",
    "def extract_clis(txt_path: str):\n",
    "    clis = []\n",
    "    with open(txt_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            if is_cli(line):\n",
    "                clis.append(line)\n",
    "    seen, unique = set(), []\n",
    "    for c in clis:\n",
    "        if c not in seen:\n",
    "            seen.add(c)\n",
    "            unique.append(c)\n",
    "    return unique\n",
    "\n",
    "def main():\n",
    "    global pdf_path, txt_path, cli_spans, texts, vector_db\n",
    "\n",
    "    txt_path = pdf_path.replace(\".pdf\", \".txt\")\n",
    "\n",
    "    # --- Load PDF into bytes (respect max_pages) ---\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader, writer = PdfReader(f), PdfWriter()\n",
    "        pages = reader.pages[:max_pages] if max_pages else reader.pages\n",
    "        for p in pages:\n",
    "            writer.add_page(p)\n",
    "        buf = io.BytesIO()\n",
    "        writer.write(buf)\n",
    "    pdf_bytes = buf.getvalue()\n",
    "\n",
    "    # --- Extract CLI spans ---\n",
    "    cli_spans = extract_colored_cli_spans(pdf_bytes)\n",
    "\n",
    "    # --- Save text & extract raw CLIs ---\n",
    "    save_pdf_as_txt(pdf_path, txt_path)\n",
    "    commands = extract_clis(txt_path)\n",
    "    with open(\"extracted_commands.txt\", \"w\") as out:\n",
    "        out.write(\"\\n\".join(commands))\n",
    "\n",
    "    # --- Convert to Docling document (text + images) ---\n",
    "    stream = io.BytesIO(pdf_bytes)\n",
    "    doc_stream = DocumentStream(\n",
    "        name=pdf_path, stream=stream, input_format=InputFormat.PDF\n",
    "    )\n",
    "    opts = PdfPipelineOptions(do_ocr=False, generate_picture_images=True)\n",
    "    converter = DocumentConverter(\n",
    "        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=opts)}\n",
    "    )\n",
    "    converted = converter.convert(source=doc_stream).document\n",
    "\n",
    "    # --- Shared doc_id counter ---\n",
    "    doc_id = 0\n",
    "\n",
    "    # --- Vision-Instruct on each image with progress bar ---\n",
    "    pictures = []\n",
    "    body_refs = converted.body.children\n",
    "    for ref in tqdm(body_refs, desc=\"Generating image JSON\"):\n",
    "        if not ref.cref.startswith(\"#/pictures/\"):\n",
    "            continue\n",
    "        page_num = int(ref.cref.split(\"/\")[2])\n",
    "        if max_pages and page_num > max_pages:\n",
    "            continue\n",
    "\n",
    "        pic_idx = int(ref.cref.split(\"/\")[-1])\n",
    "        img = converted.pictures[pic_idx].get_image(converted)\n",
    "        if not img:\n",
    "            continue\n",
    "\n",
    "        # prepare JPEG + base64\n",
    "        img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)\n",
    "        if img.mode in (\"RGBA\", \"LA\"):\n",
    "            img = img.convert(\"RGB\")\n",
    "        bio = BytesIO()\n",
    "        img.save(bio, format=\"JPEG\", quality=70)\n",
    "        b64 = base64.b64encode(bio.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        # neighboring text\n",
    "        idx_ref = body_refs.index(ref)\n",
    "        above = below = \"\"\n",
    "        if idx_ref > 0 and body_refs[idx_ref - 1].cref.startswith(\"#/texts/\"):\n",
    "            t_idx = int(body_refs[idx_ref - 1].cref.split(\"/\")[-1])\n",
    "            if not max_pages or t_idx + 1 <= max_pages:\n",
    "                above = converted.texts[t_idx].text.strip()\n",
    "        if idx_ref < len(body_refs) - 1 and body_refs[idx_ref + 1].cref.startswith(\"#/texts/\"):\n",
    "            t_idx = int(body_refs[idx_ref + 1].cref.split(\"/\")[-1])\n",
    "            if not max_pages or t_idx + 1 <= max_pages:\n",
    "                below = converted.texts[t_idx].text.strip()\n",
    "        context_text = f\"Text above:\\n{above}\\n\\nText below:\\n{below}\"\n",
    "\n",
    "        # call Watsonx vision-instruct\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Respond ONLY in JSON matching the image schema, capturing any CLI lines.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": context_text},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"project_id\": VISION_PROJECT_ID,\n",
    "            \"model_id\": VISION_MODEL_ID,\n",
    "            \"max_tokens\": 2500,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 1\n",
    "        }\n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {VISION_TOKEN}\"\n",
    "        }\n",
    "        url = \"https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2023-05-29\"\n",
    "\n",
    "        try:\n",
    "            resp = requests.post(url, headers=headers, json=payload, timeout=300)\n",
    "            resp.raise_for_status()\n",
    "            generated = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception:\n",
    "            generated = \"{}\"\n",
    "\n",
    "        # increment and assign doc_id + source\n",
    "        doc_id += 1\n",
    "        pictures.append(\n",
    "            Document(\n",
    "                page_content=generated,\n",
    "                metadata={\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"source\": pdf_path,\n",
    "                    \"type\": \"picture\",\n",
    "                    \"ref\": ref.cref,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- Chunk & annotate text with inline COLOR tags ---\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "    chunker = HybridChunker(\n",
    "        tokenizer=tokenizer, chunk_size=tokenizer.model_max_length, chunk_overlap=20\n",
    "    )\n",
    "    texts = []\n",
    "    for chunk in chunker.chunk(converted):\n",
    "        items = chunk.meta.doc_items\n",
    "        if len(items) == 1 and isinstance(items[0], TableItem):\n",
    "            continue\n",
    "        safe = tokenizer.decode(\n",
    "            tokenizer.encode(chunk.text)[:tokenizer.model_max_length],\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        ann = safe\n",
    "        for span in cli_spans:\n",
    "            if span[\"cli\"] in ann:\n",
    "                r, g, b = span[\"color\"]\n",
    "                tag = f\"<COLOR=({r},{g},{b})>{span['cli']}</COLOR>\"\n",
    "                ann = ann.replace(span[\"cli\"], tag, 1)\n",
    "\n",
    "        # increment and assign doc_id + source\n",
    "        doc_id += 1\n",
    "        texts.append(\n",
    "            LangDocument(\n",
    "                page_content=ann,\n",
    "                metadata={\"doc_id\": doc_id, \"source\": pdf_path},\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- Build vector store on text + image JSON ---\n",
    "    embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    dbf = tempfile.NamedTemporaryFile(suffix=\".db\", delete=False).name\n",
    "    vector_db = Milvus(\n",
    "        embedding_function=embed,\n",
    "        connection_args={\"uri\": dbf},\n",
    "        auto_id=True,\n",
    "        index_params={\"index_type\": \"AUTOINDEX\"},\n",
    "        enable_dynamic_field=True\n",
    "    )\n",
    "    vector_db.add_documents(texts + pictures)\n",
    "\n",
    "    print(\"Preprocessing complete; vector DB ready.\")\n",
    "\n",
    "# Execute preprocessing\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "931d755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Are there any colored CLIs?\n",
      "\n",
      "Answer: No, there are no colored CLIs.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: RAG with Annotated Context & Images ===\n",
    "\n",
    "import os, csv\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# CSV header\n",
    "output_csv=\"rag_results.csv\"\n",
    "with open(output_csv,\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    csv.writer(f).writerow([\"question\",\"answer\",\"context\"])\n",
    "\n",
    "# A static list of 30 representative CLI examples\n",
    "static_clis = [\n",
    "    \"set system host-name <hostname>\",\n",
    "    \"set system time-zone <zone>\",\n",
    "    \"set system ntp server <ntp-server-ip-addr>\",\n",
    "    \"set interfaces lo0 unit 0 family inet address <loopback0_ip_address/prefix>\",\n",
    "    \"set system services ssh\",\n",
    "    \"request chassis beacon fpc <slot> pic-slot <pic> port <port> on timer <minutes>\",\n",
    "    \"request chassis beacon fpc <slot> off\",\n",
    "    \"show firewall filter wan-in-v4-test-et-0/0/0.2001-i\",\n",
    "    \"show firewall filter wan-in-v6-in-et-0/0/0.2001-i\",\n",
    "    \"set firewall family inet filter CMU_CSID_V1100|1500|1600-INGR term BGP-IN from source-prefix-list CSID-BGP\",\n",
    "    \"set firewall family inet6 filter wan-in-v6-in term 1 from traffic-class af41\",\n",
    "    \"set firewall family inet6 filter wan-in-v6-in term 1 then count inbound-af11-v6-counter\",\n",
    "    \"set firewall family inet6 filter wan-in-v6-in term default then accept\",\n",
    "    \"set policy-options prefix-list CSID-BGP-V1100|1500|1600 <IPV4-SUBNETS>\",\n",
    "    \"set class-of-service interfaces ge-x/y/z shaping-rate 300m\",\n",
    "    \"show system software list\",\n",
    "    \"request system software add /var/tmp/junos-evo-install-acx-f... no-validate reboot\",\n",
    "    \"show chassis pic fpc-slot 0 pic-slot 0\",\n",
    "    \"set chassis alarm management-ethernet link-down ignore\",\n",
    "    \"set protocols lldp interface all disable\",\n",
    "    \"set system no-redirects\",\n",
    "    \"set system default-address-selection\",\n",
    "    \"delete chassis auto-image-upgrade\",\n",
    "    \"delete system commit factory-settings\",\n",
    "    \"set system login class REMOTE idle-timeout 15\",\n",
    "    \"set system login user <admin> encrypted-password \\\"<secret>\\\"\",\n",
    "    \"set system ports console log-out-on-disconnect\",\n",
    "    \"set system ports console type vt100\",\n",
    "    \"set interfaces et-0/0/0 unit 2001 family inet filter input wan-in-v4-test\",\n",
    "    \"set interfaces et-0/0/0 unit 2001 family inet6 filter input wan-in-v6-in\",\n",
    "]\n",
    "\n",
    "# Pre-format the examples as a bullet list\n",
    "CLI_CONTEXT = \"\\n\".join(f\"- {cmd}\" for cmd in static_clis)\n",
    "\n",
    "# Setup LLM\n",
    "API_KEY = os.getenv(\"WATSONX_API_KEY\")\n",
    "PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "token = get_iam_access_token(API_KEY)\n",
    "llm = WatsonxLLM(\n",
    "    model_id=\"meta-llama/llama-3-405b-instruct\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    apikey=API_KEY,\n",
    "    project_id=PROJECT_ID\n",
    ")\n",
    "\n",
    "\n",
    "def strip_color_tags(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove all <COLOR=(r,g,b)>…</COLOR> wrappers from the given text,\n",
    "    returning only the inner content.\n",
    "    \"\"\"\n",
    "    # This regex matches the opening tag with three digits, then captures\n",
    "    # anything (non-greedy) until the closing tag.\n",
    "    pattern = re.compile(r\"<COLOR=\\(\\d+,\\d+,\\d+\\)>(.*?)</COLOR>\")\n",
    "    # Replace each full match with just the captured group (the CLI itself)\n",
    "    return pattern.sub(r\"\\1\", text)\n",
    "\n",
    "\n",
    "def run_rag(question: str, k: int):\n",
    "    # Retrieve context from vector DB\n",
    "    docs = vector_db.as_retriever().invoke(question, k=k)\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "    # Build prompt, inserting the examples before the actual context\n",
    "    prompt = (\n",
    "        \"You are a Junos CLI expert. Use ONLY the context and inline COLOR tags to answer.\\n\"\n",
    "        \"You can use these examples to understand the CLI format:\\n\"\n",
    "        f\"{CLI_CONTEXT}\\n\\n\"\n",
    "        \"Make sure your CLI outputs do not include the color tokens; they should only contain the CLIs. For example if you want to output: 'set firewall family inet filter wan-in-v4-test term 1 then count <COLOR=(0,176,80)>inbound', instead output: 'set firewall family inet filter wan-in-v4-test term 1 then count inbound'\\n\"\n",
    "        \"You will also see descriptions of images in JSON format. Understand that these represent content of images.\"\n",
    "        f\"Context:\\n{context}\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "    )\n",
    "\n",
    "    # Invoke the LLM\n",
    "    response = llm.invoke(\n",
    "        prompt,\n",
    "        decoding_method=\"greedy\",\n",
    "        max_new_tokens=4096,\n",
    "        temperature=0\n",
    "    )\n",
    "    answer = strip_color_tags(response.strip())\n",
    "\n",
    "    # Log to CSV\n",
    "    with open(output_csv, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow([question, answer, context])\n",
    "\n",
    "    return answer, context\n",
    "\n",
    "# Example usage\n",
    "for q in [\n",
    "    \"Are there any colored CLIs?\",\n",
    "]:\n",
    "    print(f\"\\nQuestion: {q}\\n\")\n",
    "    ans,_=run_rag(q, k=5)\n",
    "    print(ans)\n",
    "    print(\"==================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
